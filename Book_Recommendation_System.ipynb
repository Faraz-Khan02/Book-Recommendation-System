{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faraz-Khan02/Book-Recommendation-System/blob/main/Book_Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Book Recommendation System**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name**   -     Faraz Faisal Khan\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation system is one of the evolving field nowadays, from e-commerce to online advertisement recommendation system is used everywhere. First of all for doing this Unsupervised learning we "
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**During the last few decades, with the rise of Youtube, Amazon, Netflix, and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\n",
        "In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy, or anything else depending on industries).\n",
        "Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors. The main objective is to create a book recommendation system for users.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import csr_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UvekSf7iTDcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "books = pd.read_csv(\"/content/drive/MyDrive/Capstone Project - 4/Books.csv\")\n",
        "users = pd.read_csv(\"/content/drive/MyDrive/Capstone Project - 4/Users.csv\")\n",
        "ratings = pd.read_csv(\"/content/drive/MyDrive/Capstone Project - 4/Ratings.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Books Data**"
      ],
      "metadata": {
        "id": "Tc2Zhksi8NNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Books data first look\n",
        "books.head()"
      ],
      "metadata": {
        "id": "_H6NvoKg8WKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, Books data contains many features which are as follows:\n",
        "\n",
        "\n",
        "*   **ISBN** : It contains ISBN number of the books which mean  International Standard Book Number.\n",
        "*   **Book-Title** : It contains title of the books.\n",
        "\n",
        "\n",
        "*   **Book-Author** : It contains the name of author of that book.\n",
        "*   **Year-Of-Publication** : It contains the year in which that book was published.\n",
        "\n",
        "\n",
        "*   **Publisher** : It contains the name of the publisher.\n",
        "*   **Image-URL-S** : It contains the Image Url of small size.\n",
        "\n",
        "\n",
        "*   **Image-URL-M** : It contains the Image Url of medium size.\n",
        "*   **Image-URL-L** : It contains the Image Url of Large size.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cDVJy0Ix9MS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of Books data\n",
        "books.shape"
      ],
      "metadata": {
        "id": "QSwqpu5S9AJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our, Books dataset contains 271360 rows and 8 columns."
      ],
      "metadata": {
        "id": "SMEBYFgoEOMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Books dataset info\n",
        "books.info"
      ],
      "metadata": {
        "id": "BhLVghq6Eeew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Books Dataset Duplicate Value Count\n",
        "duplicate = books.duplicated()\n",
        "print(duplicate.value_counts())"
      ],
      "metadata": {
        "id": "O0H1_HWVFo3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It means there is no any duplicate values in the books dataset."
      ],
      "metadata": {
        "id": "lde4UEbtIGvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "books.isnull().sum()"
      ],
      "metadata": {
        "id": "MJpm_5EkImX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Data Cleaning of Books Dataset***"
      ],
      "metadata": {
        "id": "XJxhqushL302"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, Image-URL-S, Image-URL-M, Image-URL-L are not any useful feature for our recommmendation so we will drop it."
      ],
      "metadata": {
        "id": "2OFOZqX7MD8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping last three columns \n",
        "books.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "jz9tZOnTMknW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the Books column\n",
        "books.rename(columns = {'Book-Title':'Book_Title', 'Book-Author':'Book_Author', 'Year-Of-Publication':'Year_Of_Publication'}, inplace=True)"
      ],
      "metadata": {
        "id": "_rMHhDKMdSvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing the columns name because dashed sign caused some problem further."
      ],
      "metadata": {
        "id": "R92Wwl4bdZLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# After dropping 3 columns\n",
        "books.head()"
      ],
      "metadata": {
        "id": "9nbyC_LQuCpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking data types of columns\n",
        "print(books.dtypes)"
      ],
      "metadata": {
        "id": "2lCOWFxAU4fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, Year_Of_Publication should have integer datatype but its object so we will check the unique values of it."
      ],
      "metadata": {
        "id": "uWuju04_VJtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the unique values of Year-Of-Publication\t\n",
        "books['Year_Of_Publication'].unique()"
      ],
      "metadata": {
        "id": "2cnTJPuvVy7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that 'DK Publishing Inc' and 'Gallimard' are wrong entry and we can see Year of Publication is more than 2004 which is wrong because our data was published in 2004."
      ],
      "metadata": {
        "id": "ekBldGBzZ8Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the rows having 'DK Publishing Inc' and 'Gallimard' as Year_Of_Publication\n",
        "books.loc[(books['Year_Of_Publication'] == 'DK Publishing Inc') |( books['Year_Of_Publication'] == 'Gallimard'),:]"
      ],
      "metadata": {
        "id": "2C4DZbqflQAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can clearly see that Book-Author and Year_Of_Publication is mismatched so we will replace it correctly."
      ],
      "metadata": {
        "id": "MShu3dD9lseN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correcting 1st row \n",
        "books.loc[books.ISBN == '0789466953','Year_Of_Publication'] = 2000\n",
        "books.loc[books.ISBN == '0789466953','Book_Author'] = \"James Buckley\"\n",
        "books.loc[books.ISBN == '0789466953','Publisher'] = \"DK Publishing Inc\"\n",
        "books.loc[books.ISBN == '0789466953','Book_Title'] = \"DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)\""
      ],
      "metadata": {
        "id": "wfBRJTgJnUFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correcting 2nd row\n",
        "books.loc[books.ISBN == '2070426769','Year_Of_Publication'] = 2003\n",
        "books.loc[books.ISBN == '2070426769','Book_Author'] = \"Jean-Marie Gustave Le ClÃ?Â©zio\"\n",
        "books.loc[books.ISBN == '2070426769','Publisher'] = \"Gallimard\"\n",
        "books.loc[books.ISBN == '2070426769','Book_Title'] = \"Peuple du ciel, suivi de 'Les Bergers\""
      ],
      "metadata": {
        "id": "DBC0a0R4wDvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correcting 3rd row\n",
        "books.loc[books.ISBN == '078946697X','Year_Of_Publication'] = 2000\n",
        "books.loc[books.ISBN == '078946697X','Book_Author'] = \"Michael Teitelbaum\"\n",
        "books.loc[books.ISBN == '078946697X','Publisher'] = \"DK Publishing Inc\"\n",
        "books.loc[books.ISBN == '078946697X','Book_Title'] = \"DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)\""
      ],
      "metadata": {
        "id": "zi0ggZrQs3QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rechecking after correcting\n",
        "books.loc[(books.ISBN == '0789466953') | (books.ISBN == '078946697X') | (books.ISBN == '2070426769'),:]"
      ],
      "metadata": {
        "id": "nO0uY9mswbD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting year of publication to type int\n",
        "books['Year_Of_Publication'] = books['Year_Of_Publication'].astype(int)"
      ],
      "metadata": {
        "id": "TlxC5IUMzDVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking year in sorted manner\n",
        "sorted(books['Year_Of_Publication'].unique())"
      ],
      "metadata": {
        "id": "iRmdd0T9zlgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, 0 is incorrect and our data was of 2004 and Year_Of_Publication is greater than 2004 which means it is wrongly interpreted.So, we will interpret those values with NaN. "
      ],
      "metadata": {
        "id": "VQuNGVZRz3F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing year 0 and years above 2004 with NaN\n",
        "books.loc[(books['Year_Of_Publication'] > 2004) | (books['Year_Of_Publication']==0),'Year_Of_Publication'] = np.NAN"
      ],
      "metadata": {
        "id": "UH7mEdR5z2am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Handling Missing Values***"
      ],
      "metadata": {
        "id": "ERdg5Xw64Hyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for missing values\n",
        "books.isnull().sum()"
      ],
      "metadata": {
        "id": "MU0tG9Mu396C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box plot for Year-Of-Piblication\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.boxplot(books['Year_Of_Publication'])"
      ],
      "metadata": {
        "id": "C5WM-CCpLT8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see Book Author contains '1' missing values , Year_Of_Publication contain 4690 missing values and Publisher contains '2' missing values. So, we will handle those missing values."
      ],
      "metadata": {
        "id": "Lweqy4Du4BVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputing the NaN values with medain values of Year_Of_Publication\n",
        "books['Year_Of_Publication'].fillna(round(books['Year_Of_Publication'].median()),inplace=True)"
      ],
      "metadata": {
        "id": "CxlWqObeyUji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Publisher column has 2 NaN so exploring it\n",
        "books.loc[books.Publisher.isnull(),:]"
      ],
      "metadata": {
        "id": "l6xbn84Izv0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can can fill NaN values with others."
      ],
      "metadata": {
        "id": "LeNGfuKz3bJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing missing values with 'other'\n",
        "books.loc[(books.ISBN == '193169656X'),'Publisher'] = 'other'\n",
        "books.loc[(books.ISBN == '1931696993'),'Publisher'] = 'other'"
      ],
      "metadata": {
        "id": "ItaMzpEe4NTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since, author has only 1 missing value so, we can drop that row easily."
      ],
      "metadata": {
        "id": "AMBVM_ap4eib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the missing values in 'author' column \n",
        "books.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "jW4JbmvH4nEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for missing values\n",
        "books.isnull().sum()"
      ],
      "metadata": {
        "id": "w1xZWwH_5nxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here we can clearly see that we dont have any missing values in our Books dataset."
      ],
      "metadata": {
        "id": "1hEesba4550R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Users Data**"
      ],
      "metadata": {
        "id": "V9L1h46a6V0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Users data first look\n",
        "users.head()"
      ],
      "metadata": {
        "id": "qVOoxt9k6jbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our Users dataset contains following features and they are:\n",
        "\n",
        "\n",
        "*   **User-ID** : It contains the User-Id of different Users.\n",
        "*   **Location** : It contains the location of the Users.\n",
        "\n",
        "*   **Age** : It contains the age of the Users\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k14ufcZU62S7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the Users dataset\n",
        "users.shape"
      ],
      "metadata": {
        "id": "XGdYbLkL95QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data contains 278858 rows and 3 columns."
      ],
      "metadata": {
        "id": "N--uMuGd-JND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Users dataset info\n",
        "users.info"
      ],
      "metadata": {
        "id": "l9mPbjsA-uUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Users Dataset Duplicate Value Count\n",
        "duplicate = users.duplicated()\n",
        "print(duplicate.value_counts())"
      ],
      "metadata": {
        "id": "zWjQ6-LxALDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "so, here there is no any duplicate value in our dataset."
      ],
      "metadata": {
        "id": "6RopaYU8ATiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "users.isnull().sum()"
      ],
      "metadata": {
        "id": "HOhLy0U4AyOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age has 110762 missing values which is a great number."
      ],
      "metadata": {
        "id": "RgTCVV_2BBB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Data Cleaning of Users Data***"
      ],
      "metadata": {
        "id": "BAJwryx7BOG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users.rename(columns = {'User-ID':'User_ID'}, inplace=True)"
      ],
      "metadata": {
        "id": "yVY9GL7VgChT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box plot for Age\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.boxplot(users['Age'])"
      ],
      "metadata": {
        "id": "ZifVvHAHFb_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can clearly see Age column contains lot of outliers."
      ],
      "metadata": {
        "id": "x-mxVOuoGJhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting unique age values in sorted manner\n",
        "print(sorted(users.Age.unique()))"
      ],
      "metadata": {
        "id": "2Zce9tgnDtxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, Age contains NaN values, 0 to 5 years and age greater than 90 no any user would be there who would read books. so will remove age less than 5 and age greater than 90 with NaN."
      ],
      "metadata": {
        "id": "CCRSJyQ-EDOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing age below 5 and above 90 by NaN\n",
        "users.loc[(users.Age > 90) | (users.Age < 5), 'Age'] = np.nan"
      ],
      "metadata": {
        "id": "--5_cq4lHhwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for missing values\n",
        "users.isnull().sum()"
      ],
      "metadata": {
        "id": "wcZSynYkHxoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here we will impute the missing values with mean."
      ],
      "metadata": {
        "id": "n0XIGfaiH7sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing NaN with mean\n",
        "users['Age'].fillna((users['Age'].mean()), inplace=True)"
      ],
      "metadata": {
        "id": "HZXXjLxhIgJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.head()"
      ],
      "metadata": {
        "id": "g-5KN5sdKRO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here we will change the data type of Age to int."
      ],
      "metadata": {
        "id": "3PS-vvnUKexE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the data type as int\n",
        "users.Age = users.Age.astype(np.int64)"
      ],
      "metadata": {
        "id": "yDq7nLhdKn-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for missing values\n",
        "books.isnull().sum()"
      ],
      "metadata": {
        "id": "qkE_2qdiK3Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we have cleaned our Users Dataset."
      ],
      "metadata": {
        "id": "srnFyworK5bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ratings Data**"
      ],
      "metadata": {
        "id": "g-T4-4ELYese"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ratings Data first look\n",
        "ratings.head()"
      ],
      "metadata": {
        "id": "xaQXYs28Z59j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out Ratings Dataset contains following features:\n",
        "\n",
        "\n",
        "*   **User-ID** : It contains the User-Id of different users.\n",
        "*   **ISBN** : It contains ISBN number of the books which mean International Standard Book Number.\n",
        "\n",
        "*   **Book-Rating** : It contains the rating of the book given by different users. \n",
        "\n"
      ],
      "metadata": {
        "id": "Lk12TeY2agBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of the Ratings Dataset\n",
        "ratings.shape"
      ],
      "metadata": {
        "id": "SRvq8g97cByl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset contains 1149780 rows and 3 columns."
      ],
      "metadata": {
        "id": "bnZupeNggu6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings dataset info\n",
        "ratings.info"
      ],
      "metadata": {
        "id": "MS7THkJsckDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the name of the column\n",
        "ratings.rename(columns = {'User-ID':'User_ID', 'Book-Rating':'Book_Rating'}, inplace=True)"
      ],
      "metadata": {
        "id": "KGewHdsMghfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings Dataset Duplicate Value Count\n",
        "duplicate = ratings.duplicated()\n",
        "print(duplicate.value_counts())"
      ],
      "metadata": {
        "id": "FAk9yb3Bc6qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "so, there are no any duplicate value present in our dataset."
      ],
      "metadata": {
        "id": "0a4SArDEdEKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "ratings.isnull().sum()"
      ],
      "metadata": {
        "id": "5lWlrux9ddGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here we can clearly see there is no any missing value in ratings. But ratings data contain many ISBN so, we will check it from books dataset."
      ],
      "metadata": {
        "id": "J7AOY8tAdxtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we are agregating only unique ISBN from ratings which is in books dataset\n",
        "unique_ratings = ratings[ratings.ISBN.isin(books.ISBN)]"
      ],
      "metadata": {
        "id": "aWGRjdNfJ1Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ratings dataset should have ratings from users which exist in users dataset, unless new users or book are added to users dataset."
      ],
      "metadata": {
        "id": "l267C77bMBLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataframe which contains books that are only in books dataset\n",
        "ratings = ratings[ratings.User_ID.isin(users.User_ID)]"
      ],
      "metadata": {
        "id": "FxCMCwNEX_sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "Rffw1_q0MTz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***EDA on Books Data***"
      ],
      "metadata": {
        "id": "435wlY3_50RE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 10 Books"
      ],
      "metadata": {
        "id": "iWGpvjOiNVxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 Books\n",
        "ax = books['Book_Title'].value_counts()[:10].plot(kind = 'barh', legend = False, figsize = (12,6))\n",
        "plt.title('Top 10 books')"
      ],
      "metadata": {
        "id": "6nhnqM0VMw04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above visualization we infer that **Great Expectations**, **Pride and Prejudice**, **The Night Before Christmas**, **Jane Eyre**, **Adventures of Huckleberry Finn**, **The Secret Garden**, **Dracula**, **Wuthering heights**, **Little Women** and **Selected Poems** are the top 10 books in our dataset."
      ],
      "metadata": {
        "id": "8zGtZmX0NeiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 10 Authors"
      ],
      "metadata": {
        "id": "raYIu7mQ69Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing top 10 authors\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(y='Book_Author',data=books,order=pd.value_counts(books['Book_Author']).iloc[:10].index)\n",
        "plt.title('Top 10 Authors')"
      ],
      "metadata": {
        "id": "s_Z9eiqC6vX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our Countplot we can infer that **Agatha Christie**, **William Shakespeare**, **Stephen King**, **Ann M Martin**, **Carolyn Keene**, **Francine Pascal**, **Isaac Asimov**, **Nora Roberts**, **Barbara Cartiand** and **Charles Dickens** are the top Authors."
      ],
      "metadata": {
        "id": "NQra0Kuk8QNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 10 Publishers"
      ],
      "metadata": {
        "id": "vf6AeGrj982c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing top 10 Publisher\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(y='Publisher',data=books,order=pd.value_counts(books['Publisher']).iloc[:10].index)\n",
        "plt.title('Top 10 Publishers')"
      ],
      "metadata": {
        "id": "LSoyTm91-GHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our countplot we infer that **Harlequin**, **Silhouette**, **Pocket**, **Ballantine Books**, **Bantam Books**, **Scholastic**, **Simon &amp Schuster**, **Penguin Books**, **Berkley Publishing Group** and **Warner Books** are the top 10 publishers."
      ],
      "metadata": {
        "id": "03789Djq-vzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Books Published in that Year"
      ],
      "metadata": {
        "id": "EGjtj7N1EfdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the no. of books published each year through histogram\n",
        "sns.set_style('darkgrid')\n",
        "fig, ax =plt.subplots()\n",
        "fig.set_size_inches(12,8)\n",
        "sns.histplot(books['Year_Of_Publication'],bins=np.arange(1900,2004,3),color='r')\n",
        "plt.ylabel('No. of Books Published')\n",
        "plt.xlabel('Year')\n",
        "plt.title('Visualizing the total no. of books published each year')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZW_Zp7fnDejm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our visualization we can say that in 2000 most no. of books was Published."
      ],
      "metadata": {
        "id": "yrvPYl19Evfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***EDA on Users Data***"
      ],
      "metadata": {
        "id": "1DnFq_j5FMcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Which Age category reads the book most?"
      ],
      "metadata": {
        "id": "jD19YI3CJn6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting histogram of age distribution\n",
        "fig = plt.figure(figsize = (12,8))\n",
        "users.Age.hist(bins=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
        "plt.title('Age Distribution\\n')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0OLXP__LMoU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our histogram plotting we can see that mpst of the Users are from 30 - 40."
      ],
      "metadata": {
        "id": "WBN81GhDNRj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting pie chart for above graph\n",
        "fig = plt.figure(figsize = (12,12))\n",
        "users.Age.value_counts().plot.pie(autopct='%1.1f%%',shadow=True)\n",
        "plt.title('Age of Users')\n",
        "\n"
      ],
      "metadata": {
        "id": "8DjcVkGMNysE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this we can clearly see 41.9% of users are age 34 this is becuase we have imputed mean value in it."
      ],
      "metadata": {
        "id": "h5Ls-vaJOqhJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 10 cities for Maximum Readers"
      ],
      "metadata": {
        "id": "mHl6JU50KZJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Top 10 location where most no. of users recide\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(x=\"Location\", data=users,order=users['Location'].value_counts().index[0:10])\n",
        "plt.title(\"Top 10 cities for maximum readers\")"
      ],
      "metadata": {
        "id": "VOSlXgx-KZ_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EDA on Ratings Data**"
      ],
      "metadata": {
        "id": "1kEaOG_3LzJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above plot we infer that **london, england, united kingdom** is place where most number of users recide."
      ],
      "metadata": {
        "id": "1lNbUqqqLRzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting count of rating to see how it's distributed\n",
        "fig = plt.figure(figsize = (12,6))\n",
        "sns.countplot(x='Book_Rating',data=ratings)\n",
        "plt.title(\"Rating plot\")"
      ],
      "metadata": {
        "id": "dQJ0kF7jKC4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see 0 is the most in our rating dataset which means most of the users did not give any review. Now we have to separate the explicit ratings represented by 1–10 and implicit ratings represented by 0."
      ],
      "metadata": {
        "id": "j5n1aOPeMNdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating ratings\n",
        "ratings_explicit= unique_ratings[unique_ratings['Book_Rating'] != 0]\n",
        "ratings_implicit= unique_ratings[unique_ratings['Book_Rating'] == 0]"
      ],
      "metadata": {
        "id": "n-1GYSfeKClZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting count of rating to see how it's distributed\n",
        "fig = plt.figure(figsize = (12,6))\n",
        "sns.countplot(x='Book_Rating',data=ratings_explicit)\n",
        "plt.title(\"Rating plot\")"
      ],
      "metadata": {
        "id": "72vKo25KRk_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this visualization we can see 8 is the most common rating given by the users and most of the ratings lie between 7 - 10."
      ],
      "metadata": {
        "id": "aSN9CLSiSSgT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Popularity Based Recommendation System**"
      ],
      "metadata": {
        "id": "rht8VgLuux9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Popularity based recommendation system works with the current vogue. It basically uses the items which are in swing at present. This is the most basic recommendation system which provides generalized recommendation to every user depending on the popularity. Whatever is more popular among the general public that is more likely to be recommended to new customers. The generalized recommendation not personalized is based on the count."
      ],
      "metadata": {
        "id": "wonzJFwpvSh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Viewing our explicit dataset\n",
        "ratings_explicit.head()"
      ],
      "metadata": {
        "id": "1YQaUe9UvtbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging ratings_explicit with books dataset on ISBN feature\n",
        "new_book= pd.merge(books, ratings_explicit, on='ISBN')\n",
        "new_book.head()"
      ],
      "metadata": {
        "id": "61GApWSdMaE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since, Book and Users data have both ISBN as common feauture so, we explicitily merged both the datasets."
      ],
      "metadata": {
        "id": "BgmIJT_QMyPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of new_book data\n",
        "new_book.shape"
      ],
      "metadata": {
        "id": "dxhn-LFINL8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, here new_book data contains 383841 rows and 7 columns. "
      ],
      "metadata": {
        "id": "C7HQUxl6NXXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping new_book data based on title and aggregate based on rating\n",
        "top_ten_books= pd.DataFrame(new_book.groupby('Book_Title')['Book_Rating'].count().sort_values(ascending=False).head(10))"
      ],
      "metadata": {
        "id": "brEronp3OA3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing top ten books \n",
        "print('The top ten books recommendations are :')\n",
        "top_ten_books"
      ],
      "metadata": {
        "id": "NpoHmOaPPfqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We, can see clearly our top 10 books acoording to rating of the users. Then also we will see it by visualizing with a plot."
      ],
      "metadata": {
        "id": "v5oudPCyPj5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the index  \n",
        "top_ten_books=top_ten_books.reset_index() "
      ],
      "metadata": {
        "id": "r1qkDnPfRQUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting horizontal bar blot\n",
        "plt.figure(figsize=(12, 8))\n",
        "g=sns.barplot(x='Book_Rating',y='Book_Title',data=top_ten_books, palette=\"Oranges\")\n",
        "plt.title(\"Top Ten Books\")"
      ],
      "metadata": {
        "id": "I4qiwUmRQh5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our Recommendation System we infer that following books are mostly recommended books:\n",
        "\n",
        "1.   The Lovely Bones: A Novel \n",
        "2.   Wild Animus\n",
        "\n",
        "1.   The Da Vinci Code\n",
        "2.   The Secret Life of Bees\n",
        "\n",
        "1.   The Nanny Diaries: A Novel\n",
        "2.   The Red Tent(Bestselling Backlist)\n",
        "\n",
        "1.   Bridget Jones Diary\n",
        "2.   A Painted House\n",
        "\n",
        "1.   Life of Pie\n",
        "2.   Harry Potter and the Chamber of Secrets( Book 2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4QZOR97QRkz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Collaborative Filtering using KNN**"
      ],
      "metadata": {
        "id": "VqZyHO2JTPcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This filtering method is usually based on collecting and analyzing information on user’s behaviors, their activities or preferences, and predicting what they will like based on the similarity with other users. A key advantage of the collaborative filtering approach is that it does not rely on machine analyzable content and thus it is capable of accurately recommending complex items such as movies without requiring an “understanding” of the item itself."
      ],
      "metadata": {
        "id": "S5638g9AVKDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Here we assume that users who given ratings more than 200 are users who read atleast 20 books.For statisfical significance we should consider only the data of user who given more than 200 ratings."
      ],
      "metadata": {
        "id": "8Uo3CQWzZS12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Users with more than 200 ratings \n",
        "numbers1 = ratings_explicit['User_ID'].value_counts()\n",
        "ratings = ratings_explicit[ratings_explicit['User_ID'].isin(numbers1[numbers1 >= 200].index)]\n",
        "#Books with more than 100 Ratings\n",
        "number2 = ratings_explicit['Book_Rating'].value_counts()\n",
        "ratings = ratings_explicit[ratings_explicit['Book_Rating'].isin(number2[number2 >= 100].index)]"
      ],
      "metadata": {
        "id": "o4ByWorqtd0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I have taken rating >= 200 and excluded rating <= 100."
      ],
      "metadata": {
        "id": "rMbGyPAWuDVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging the dataset ratings and Books\n",
        "books_with_rating = pd.merge(ratings, books, on='ISBN')\n",
        "books_with_rating.head()"
      ],
      "metadata": {
        "id": "ZtnAVdQhxfk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we have merged book and ratings data with the help of ISBN which are in common."
      ],
      "metadata": {
        "id": "CKy3ZVYZxtGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping it with Book-Title and Book-Ratings  \n",
        "rating_count_df =books_with_rating.groupby('Book_Title')['Book_Rating'].count().reset_index()"
      ],
      "metadata": {
        "id": "QUgGeuvJzgzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I grouped the Book-Title and Book-rating because we need to predict the books on the basis of ratings."
      ],
      "metadata": {
        "id": "QaR5NlZR0NEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the rating_count_df contain\n",
        "rating_count_df.head()"
      ],
      "metadata": {
        "id": "Wkonoduh0uUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, it only contain Book_Title and Book_Rating which we need in our Recommendation System."
      ],
      "metadata": {
        "id": "QIrG0EXZ0977"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Renaming the column Book-rating with Total-Rating\n",
        "rating_count_df.rename(columns={'Book_Rating':'Total_Ratings'},inplace=True)"
      ],
      "metadata": {
        "id": "bI01J_YG-19g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging the dataframes\n",
        "total_Rating_Count = books_with_rating.merge(rating_count_df, left_on = 'Book_Title', right_on = 'Book_Title', how = 'left')\n",
        "total_Rating_Count.head()"
      ],
      "metadata": {
        "id": "BA_nZS2WAwts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we have merged two datasets books_with_rating and rating_count_df to know the popular books."
      ],
      "metadata": {
        "id": "UeajXegrBdEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we wil keep only those books which are more popular according to total_book_rating.\n"
      ],
      "metadata": {
        "id": "U8jyXKs8CQX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Keeping threshold value 50 \n",
        "popularity_threshold = 50\n",
        "rating_popular_book = total_Rating_Count.query('Total_Ratings >= @popularity_threshold')\n",
        "rating_popular_book.head()"
      ],
      "metadata": {
        "id": "aC6GZPlFDCtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, two daatframes are merged now its time to merge users dataframe to our rating_popular_book."
      ],
      "metadata": {
        "id": "RhkhOYZ5tD-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging all the three data sets\n",
        "merged_data = rating_popular_book.merge(users, left_on = 'User_ID', right_on = 'User_ID', how = 'left')"
      ],
      "metadata": {
        "id": "73xx8FZ9uaHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merged data contain\n",
        "merged_data.head()"
      ],
      "metadata": {
        "id": "a2nj2zCkuuiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see that our merged_data contains all  the necessary columns which is required for our recommendation sytem. The following features are User_ID, ISBN, Book_Rating, Book_Title, Book_Author, Year_Of_Publication, Publisher, Total_Ratings, Location and Age."
      ],
      "metadata": {
        "id": "w3CPgkZxvhkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ratings Dataset Duplicate Value Count\n",
        "duplicates = merged_data.duplicated()\n",
        "print(duplicates.value_counts())"
      ],
      "metadata": {
        "id": "9TQYSKarx9og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping duplicate values from the merged data \n",
        "merged_data.drop_duplicates(['User_ID','Book_Title'],inplace=True)"
      ],
      "metadata": {
        "id": "mH4UZE7oxW5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, dropping the duplicate value if they are present while merging our our dataset."
      ],
      "metadata": {
        "id": "GAEcoKpFyYO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating pivot table\n",
        "pivot_matrix=merged_data.pivot(index='Book_Title',values='Book_Rating',columns='User_ID')"
      ],
      "metadata": {
        "id": "GHqX6hb8EGUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we have created pivot table of merged data where we passed index for Book_Title, values for Book_Rating, Column as User_ID."
      ],
      "metadata": {
        "id": "VMCiA4wrGFKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pivot_matrix overview\n",
        "pivot_matrix.head()"
      ],
      "metadata": {
        "id": "iVIwziHiHMiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, most of the ratings are NaN which means there is absence of ratings."
      ],
      "metadata": {
        "id": "1cze_dIDILnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputing Nan values to 0\n",
        "pivot_matrix.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "A3Qid01JIfrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing pivot_matrix after imputing 0\n",
        "pivot_matrix.head()"
      ],
      "metadata": {
        "id": "7Kkf-YuqIspp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# csr is compressed sparse row because pivot_marrix is a sparse matrix\n",
        "book_sparse = csr_matrix(pivot_matrix)"
      ],
      "metadata": {
        "id": "4RpzXlmELRMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If most of the elements in the matrix are zero then the matrix is called a sparse matrix. It is wasteful to store the zero elements in the matrix since they do not affect the results of our computation.\n",
        "\n",
        "So, here we have used csr_matrix to remove zeroes from pivot_matrix."
      ],
      "metadata": {
        "id": "3rG_EmOmVG_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling with KNN\n",
        "Recommendation_model = NearestNeighbors(metric = 'cosine',algorithm='brute')"
      ],
      "metadata": {
        "id": "CbWBYRGYZ986"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we have used evaluation metric **cosine** which is used for determining the distance between the neighbors, in recommendation systems. "
      ],
      "metadata": {
        "id": "QAGtaEKQZ9JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model \n",
        "Recommendation_model.fit(book_sparse)"
      ],
      "metadata": {
        "id": "DIwFAruJmeFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating random book \n",
        "random_book = np.random.choice(pivot_matrix.shape[0])\n",
        "print(random_book)\n",
        "print(pivot_matrix.iloc[random_book,:].values.reshape(1,-1))\n",
        "#Apply the k neighbors to fiited model this will create clusters\n",
        "distances, indices = Recommendation_model.kneighbors(pivot_matrix.iloc[random_book,:].values.reshape(1, -1), n_neighbors = 6)\n",
        "pivot_matrix.index[random_book]"
      ],
      "metadata": {
        "id": "lawD_-C4nn8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we choose any random book for which we need to recommend the book."
      ],
      "metadata": {
        "id": "uyYLXHiPwQDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the random book name and suggested books.\n",
        "for i in range(0, len(distances.flatten())):\n",
        "    if i == 0:\n",
        "        print('Recommendations for {0}:\\n'.format(pivot_matrix.index[random_book]))\n",
        "    else:\n",
        "        print('{0}: {1}, with distance of {2}:'.format(i, pivot_matrix.index[indices.flatten()[i]], distances.flatten()[i]))"
      ],
      "metadata": {
        "id": "mXzWgu8ioK17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, are the 5 recommended books which is been recommended by our recommendation system."
      ],
      "metadata": {
        "id": "er59_gWZ1OkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to get recommandation for known books from our dataset\n",
        "def recommend_books(book_name):\n",
        "   Book_ID = np.where(pivot_matrix.index==book_name)[0][0]\n",
        "   print(Book_ID)\n",
        "   distances ,suggestions = Recommendation_model.kneighbors(pivot_matrix.iloc[Book_ID,:].values.reshape(1,-1),n_neighbors = 6)\n",
        "   \n",
        "   for i in range(0, len(distances.flatten())):\n",
        "    if i == 0:\n",
        "        print('Recommendations for {0}:\\n'.format(pivot_matrix.index[Book_ID]))\n",
        "    else:\n",
        "        print('{0}: {1}, with distance of {2}:'.format(i, pivot_matrix.index[suggestions.flatten()[i]], distances.flatten()[i]))"
      ],
      "metadata": {
        "id": "7WFgMFoe3wC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we have written function to recommend the model based on which book we have chosen."
      ],
      "metadata": {
        "id": "wnmxN8XO4b9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Geting recommandation for book '4 Blondes'\n",
        "recommend_books('4 Blondes')"
      ],
      "metadata": {
        "id": "leG5xPZc5V1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are our 5 recommended books by our recommendation system. Here evalaution metric is near to 1 which means it is a good model."
      ],
      "metadata": {
        "id": "p-2eWtDrEsEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Collaborative Filtering using SVD(Singular Value Decomposition)**"
      ],
      "metadata": {
        "id": "iebz75nlGs4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Singular Value Decomposition (SVD) is one of the common matrix factorization methods used in collaborative filtering, which introduces the bias information of users and items and is realized by using algebraic feature extraction. The derivative model SVD++ of SVD achieves better predictive accuracy due to the addition of implicit feedback information."
      ],
      "metadata": {
        "id": "644sVd5PKJMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For recommendation system we have to install surprise."
      ],
      "metadata": {
        "id": "NjhSJJJeLFGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing surprise\n",
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "id": "_rWTh22oMjWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We, have successfully installed surprise.\n",
        "\n",
        "Here, surprise stands for Simple Python Recommendation System Engine.\n",
        "\n",
        "Surprise is a Python scikit building and analyzing recommender systems that deal with explicit rating data."
      ],
      "metadata": {
        "id": "Y5xrHAPyOGbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Reader & Dataset from surprise\n",
        "from surprise import Reader, Dataset\n",
        "# Creating a 'Reader' object to set the limit of the ratings \n",
        "reader = Reader(rating_scale=(1, 10))\n",
        "# Loading our ratings_explicit data\n",
        "data = Dataset.load_from_df(merged_data[['User_ID', 'ISBN', 'Book_Rating']], reader)"
      ],
      "metadata": {
        "id": "gN5EOS7_XA8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing SVD model\n",
        "from surprise import SVD, model_selection, accuracy, NMF\n",
        "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV"
      ],
      "metadata": {
        "id": "SUBykKdIXNqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using  SVD algorithm\n",
        "model_svd = SVD()"
      ],
      "metadata": {
        "id": "xXLlKDtYX29v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have passed SVD() to model variable."
      ],
      "metadata": {
        "id": "BLZk9LMnX-nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying cross validation\n",
        "cv_results_svd = cross_validate(model_svd, data, cv=3)\n",
        "pd.DataFrame(cv_results_svd).mean()"
      ],
      "metadata": {
        "id": "55U0SkMsRvoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying NMF\n",
        "model_nmf = NMF()\n",
        "cv_results_nmf = cross_validate(model_nmf, data, cv=3)\n",
        "pd.DataFrame(cv_results_nmf).mean()"
      ],
      "metadata": {
        "id": "x3pIQm-5UEHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NMF stands for Latent Semantic Analysis with the ‘Non-negative Matrix-Factorization’ method used to decompose the document-term matrix into two smaller matrices — the document-topic matrix (U) and the topic-term matrix (W) — each populated with unnormalized probabilities."
      ],
      "metadata": {
        "id": "9B8H8IUeU2Cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimising the svd model\n",
        "param_grid = {'n_factors': [80,100],\n",
        "              'n_epochs': [5, 20],\n",
        "              'lr_all': [0.002, 0.005],\n",
        "              'reg_all': [0.2, 0.4]}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "print(gs.best_score['rmse'])\n",
        "print(gs.best_params['rmse'])"
      ],
      "metadata": {
        "id": "7Z7S9_BFVwAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, best Root Mean Square Error is 1.63  and best parameters which are as follows: m_factors is 80, n_epochs is 20, lr_all is 0.005, reg_all is 0.2."
      ],
      "metadata": {
        "id": "5Vgj9OlPWdDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Appying train_test_split\n",
        "X_train, y_test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "model = SVD(n_factors=80, n_epochs=20, lr_all=0.005, reg_all=0.2)\n",
        "model.fit(X_train)\n",
        "predictions = model.test(y_test) "
      ],
      "metadata": {
        "id": "LA33H4HiYQDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the books\n",
        "pred_df = pd.DataFrame(predictions, columns=['User_ID', 'ISBN', 'Actual_Rating', 'Pred_Rating','Details'])\n",
        "pred_df['Pred_Rating_Round'] = pred_df['Pred_Rating'].round()\n",
        "pred_df['Abs_Error'] = abs(pred_df['Pred_Rating'] - pred_df['Actual_Rating'])\n",
        "pred_df.sample(5)"
      ],
      "metadata": {
        "id": "qFRjTJnNaZUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see that it has predicted well according to our Actual_rating and Predicted_rating."
      ],
      "metadata": {
        "id": "RDM9GVwmf_oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will visualize absolute erroe and mean absolute error."
      ],
      "metadata": {
        "id": "6WCN9tBnhwFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping \n",
        "df_pred_err = pred_df.groupby('Actual_Rating')['Abs_Error'].mean().reset_index() \n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
        "\n",
        "# Ploting a distplot for Absolute Error\n",
        "sns.distplot(pred_df['Abs_Error'], color='green', ax=ax1)\n",
        "ax1.set_title('Distribution of Absolute Error')\n",
        "\n",
        "# Ploting Barplot for Mean Absolute error\n",
        "palette = sns.color_palette(\"RdBu\", 10)\n",
        "sns.barplot(x='Actual_Rating', y='Abs_Error', data=df_pred_err, palette=palette, ax=ax2)\n",
        "ax2.set_title('Mean Absolute Error for rating')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uEuwG7BmhuvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see that the distribution of absolute error is right-skewed, showing that the majority of errors is small: between 0 and 1. There is a long tail that indicates that there are several observations for which the absolute error was close to 10."
      ],
      "metadata": {
        "id": "lwTSe6dPoKhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging pred_df and df_books\n",
        "df_books = books.copy()\n",
        "df_new = merged_data.merge(df_books[['ISBN', 'Book_Title']], on='ISBN', how='left')\n",
        "df_new = df_new.merge(pred_df[['ISBN', 'User_ID', 'Pred_Rating']], on=['ISBN', 'User_ID'], how='left')"
      ],
      "metadata": {
        "id": "bmE6SKippl1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we have merged our df_books and merged data with pred_df to get proper Book_Title and Book_Rating."
      ],
      "metadata": {
        "id": "3-MCcrFJq3qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# viewing our df_new\n",
        "df_new.head()"
      ],
      "metadata": {
        "id": "ue8LPMOrr1mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking any User_ID  to train our model.\n",
        "selected_user_id = 225379\n",
        "df_user = df_new[df_new['User_ID']==selected_user_id]\n",
        "\n",
        "df_user[(df_user['Pred_Rating'].isna())&(df_user['Book_Rating']>=9)].sample(5)"
      ],
      "metadata": {
        "id": "3Gzn5ghXreX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set\n",
        "df_user[df_user['Pred_Rating'].notna()].sort_values('Pred_Rating', ascending=False).head(3)"
      ],
      "metadata": {
        "id": "-kMZ3Wjptnnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual set\n",
        "df_user[df_user['Pred_Rating'].notna()].sort_values('Book_Rating', ascending=False).head(3)"
      ],
      "metadata": {
        "id": "tODiENxTvFke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can clearly see our books are recommended well by our recommendation system. Its seems SVD be the best model among all."
      ],
      "metadata": {
        "id": "L5esxB1AwArU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   After doing EDA we found following conclusions:\n",
        "\n",
        "  *   Great Expectations, Pride and Prejudice, The Night Before Christmas were the top 3 books in our books dataset.\n",
        "  *   Agatha Christie, William Shakespeare, Stephen King were the top 3 authors in our books dataset.\n",
        "\n",
        "  *   Harlequin, Silhouette, Pocket are the top 3 book publisheres in our books dataset. \n",
        "  *   Most of the users were from age group between 30-40.\n",
        "\n",
        "  *   Most of the rating was found to be 8.\n",
        "\n",
        "\n",
        "*   After applying Popularity based recommendation system The Lovely Bones: A Novel, Wild Animus, The Da Vinci Code are the 3 most popular book recommended by our recommendation system.\n",
        "*   SVD is best model among all because it predicted well. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}